{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corenlp\n",
    "import numpy as np\n",
    "from nltk.tree import Tree\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF\n",
    "import json\n",
    "import queue\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constant definition\n",
    "STOPWORDS = stopwords.words('english')\n",
    "PUNCTUATIONS = [',','.',':',';','?','(',')','[',']','&','!','*','@','#','$','%']\n",
    "QUESTIONTYPE = ['what','who','where','when','how','why','which','other']\n",
    "TIME = ['DATE','DURATION','TIME']\n",
    "NUMERICAL = ['MONEY','NUMBER','ORDINAL','PERCENT'] \n",
    "MAX_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#structure definition\n",
    "class question_span:\n",
    "    def __init__(self):\n",
    "        self.content = \"\"\n",
    "        self.substiSection = \"\"\n",
    "        self.questiontype = \"\"\n",
    "\n",
    "class answer_span:\n",
    "    def __init__(self):\n",
    "        self.tokens = []\n",
    "        self.answertype = \"\"\n",
    "\n",
    "class text_span:\n",
    "    def __init__(self):\n",
    "        self.tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get tokens corresponding to an NP non-terminals from a document parse Tree \n",
    "#e.g. given [NP([NP([DT([The])],[NNS([writings])])],[PP([IN([of])],[NP([NNP(Samuel)],[NNP(Pepys)])])])]\n",
    "#e.g. given [NP([NNP(Samuel)],[NNP(Pepys)])]\n",
    "#the function will return [Samuel Pepys] as an integration\n",
    "def getNPFromTree(root):\n",
    "    result = \"\"\n",
    "    if len(root.child) > 0:\n",
    "        for node in root.child:\n",
    "            if node.value == \"NP\":\n",
    "                return \"\", False\n",
    "            res, found = getNPFromTree(node)\n",
    "            if not found:\n",
    "                return \"\", False\n",
    "            else:\n",
    "                result += res + \" \"\n",
    "        return result, True\n",
    "    else:\n",
    "        return root.value, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get tokens corresponding to an WHNP non-terminals from a document parse Tree \n",
    "#e.g. given child [WHNP([WDT(Which)],[NN(prize)])]\n",
    "#the fucntion will return [Which prize] as an integration\n",
    "def getWHNPFromTree(root):\n",
    "    result = \"\"\n",
    "    if len(root.child) > 0:\n",
    "        for node in root.child:\n",
    "            if node.value == \"WHNP\":\n",
    "                return \"\", False\n",
    "            res, found = getNPFromTree(node)\n",
    "            if not found:\n",
    "                return \"\", False\n",
    "            else:\n",
    "                result += res + \" \"\n",
    "        return result, True\n",
    "    else:\n",
    "        return root.value, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the parse tree to get all NP tokens\n",
    "#e.g. given a sentence that \"The writings of Samuel Pepys describe the pub as the heart of England.\"\n",
    "#the function will return [[The writings], [the pub], [Samuel Pepys], [the heart], [England]] consisting of 5 NP \n",
    "def getAllNPTokens(bfs):\n",
    "    np = queue.Queue(maxsize=MAX_SIZE)\n",
    "    while not bfs.empty():\n",
    "        node = bfs.get()\n",
    "        if node.value == \"NP\":\n",
    "            np.put(node)\n",
    "        if len(node.child) > 0:\n",
    "            for child in node.child:\n",
    "                bfs.put(child)\n",
    "    \n",
    "    nps = []\n",
    "    while not np.empty():\n",
    "        node = np.get()\n",
    "        res, found = getNPFromTree(node)\n",
    "        if found:\n",
    "            nps.append(res.split())\n",
    "    \n",
    "    return nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the parse tree to get all WHNP tokens\n",
    "#e.g. given a sentence that \"Which prize did Frederick Buechner create?\"\n",
    "#the function will return [Which prize] which is a single WHNP\n",
    "def getAllWHNPTokens(bfs):\n",
    "    whnp = queue.Queue(maxsize=MAX_SIZE)\n",
    "    while not bfs.empty():\n",
    "        node = bfs.get()\n",
    "        if node.value == \"WHNP\":\n",
    "            whnp.put(node)\n",
    "        if len(node.child) > 0:\n",
    "            for child in node.child:\n",
    "                bfs.put(child)\n",
    "    \n",
    "    whnps = []\n",
    "    while not whnp.empty():\n",
    "        node = whnp.get()\n",
    "        res, found = getWHNPFromTree(node)\n",
    "        if found:\n",
    "            whnps.append(res.split())\n",
    "    \n",
    "    return whnps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a candidate answer consists of answer type and answer tokens\n",
    "#e.g. [\"Samuel\", \"Pepys\"] PERSON\n",
    "#e.g. [\"the\", \"pub\"] O\n",
    "def genCandidateAnswerSpans(l1, l2):\n",
    "    count = defaultdict(int)\n",
    "    spans = []\n",
    "    \n",
    "    for sentence in l1:\n",
    "        span = answer_span()\n",
    "        for token in sentence:\n",
    "            span.tokens.append(token)\n",
    "            for token2 in l2:\n",
    "                t = token2.word\n",
    "                if token == t:\n",
    "                    if token2.ner != \"0\":\n",
    "                        span.answertype = token2.ner\n",
    "                    break\n",
    "        spans.append(span)\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genSpans(l1, l2):\n",
    "    count = defaultdict(int)\n",
    "    spans = []\n",
    "    \n",
    "    for sentence in l1:\n",
    "        span = text_span()\n",
    "        for token in sentence:\n",
    "            span.tokens.append(token)\n",
    "            for token2 in l2:\n",
    "                t = token2.word\n",
    "                if token == t:\n",
    "                    break\n",
    "        spans.append(span)\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since when we attempt to select a best answer from candidates \n",
    "#we will replace tokens in WH- or How with each candidates to get similarity score using tf-idf,\n",
    "#we need to find a valid part to replace.\n",
    "#e.g. Question: \"Which prize did Frederick Buechner create?\"\n",
    "#The function will return \"Which prize\".\n",
    "#Then we will replace \"which prize \" with each candidates, then we get a new sentence \"Buechner Prize for Preaching did Frederick Buechner create\"\n",
    "def getReplacedPart (question, questionType):\n",
    "    target = \"\"\n",
    "    q = queue.Queue(maxsize=MAX_SIZE)\n",
    "    tree = question.parseTree\n",
    "    q.put(tree)\n",
    "    \n",
    "    tokens = getAllWHNPTokens(q)\n",
    "    spans = genSpans(tokens, question.token)\n",
    "    \n",
    "    if questionType == 6:\n",
    "        target = \"which\"\n",
    "        index = 0\n",
    "        for j in range(len(spans)):\n",
    "            tempSentence = \" \".join(spans[j].tokens)\n",
    "            if \"which\" in tempSentence:\n",
    "                index = j\n",
    "                break\n",
    "        if spans:\n",
    "            target = \" \".join(spans[index].tokens)\n",
    "        else:\n",
    "            target = \"which\"\n",
    "    elif questionType == 7:\n",
    "        target = \"what\"\n",
    "        index = 0\n",
    "        for j in range(len(spans)):\n",
    "            tempSentence = \" \".join(spans[j].tokens)\n",
    "            if \"what\" in tempSentence:\n",
    "                index = j\n",
    "                break\n",
    "        if spans:\n",
    "            target = \" \".join(spans[index].tokens)\n",
    "        else:\n",
    "            target = \"what\"\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestAnswer(caSpans, qSpans, context, model):\n",
    "    score = []\n",
    "    indices = []\n",
    "    resi = 0\n",
    "    \n",
    "    questionType = qSpans.questionType\n",
    "    question = qSpans.content\n",
    "    \n",
    "    if questionType == 1:\n",
    "        for j in range(len(caSpans)):\n",
    "            caSpan = caSpans[j]\n",
    "            tokens = caSpan.tokens\n",
    "            catype = caSpan.answertype\n",
    "            if catype == \"PERSON\":\n",
    "                tempStr = question.replace('who', \" \".join(tokens))\n",
    "                x = model.fit_transform([context, tempStr])\n",
    "                matrix = (x * x.T).A\n",
    "                score.append(matrix[0][1])\n",
    "                indices.append(j)\n",
    "        score = np.array(score)\n",
    "        if len(score) > 0:\n",
    "            maxi = np.argmax(score)\n",
    "            resi = indices[maxi]\n",
    "        else:\n",
    "            try:\n",
    "                resi = random.randint(0, len(caSpans) - 1)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    elif questionType == 2:\n",
    "        for j in range(len(caSpans)):\n",
    "            caSpan = caSpans[j]\n",
    "            tokens = caSpan.tokens\n",
    "            catype = caSpan.answertype\n",
    "            if catype == \"LOCATION\" or catype == \"ORGANIZATION\":\n",
    "                tempStr = question.replace('where', \" \".join(tokens))\n",
    "                x = model.fit_transform([context, tempStr])\n",
    "                matrix = (x * x.T).A\n",
    "                score.append(matrix[0][1])\n",
    "                indices.append(j)\n",
    "        score = np.array(score)\n",
    "        if len(score) > 0:\n",
    "            maxi = np.argmax(score)\n",
    "            resi = indices[maxi]\n",
    "        else:\n",
    "            try:\n",
    "                resi = random.randint(0, len(caSpans) - 1)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "    elif questionType == 3:\n",
    "        for j in range(len(caSpans)):\n",
    "            caSpan = caSpans[j]\n",
    "            tokens = caSpan.tokens\n",
    "            catype = caSpan.answertype\n",
    "            if catype in TIME:\n",
    "                tempStr = question.replace('when', \" \".join(tokens))\n",
    "                x = model.fit_transform([context, tempStr])\n",
    "                matrix = (x * x.T).A\n",
    "                score.append(matrix[0][1])\n",
    "                indices.append(j)\n",
    "        score = np.array(score)\n",
    "        if len(score) > 0:\n",
    "            maxi = np.argmax(score)\n",
    "            resi = indices[maxi]\n",
    "        else:\n",
    "            try:\n",
    "                resi = random.randint(0, len(caSpans) - 1)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    elif questionType == 6:\n",
    "        for j in range(len(caSpans)):\n",
    "            caSpan = caSpans[j]\n",
    "            tokens = caSpan.tokens\n",
    "            catype = caSpan.answertype\n",
    "            tempStr = question.replace(qSpans.substiSection, \" \".join(tokens))\n",
    "            x = model.fit_transform([context, tempStr])\n",
    "            matrix = (x * x.T).A\n",
    "            score.append(matrix[0][1])\n",
    "            indices.append(j)\n",
    "        score = np.array(score)\n",
    "        if len(score) > 0:\n",
    "            maxi = np.argmax(score)\n",
    "            resi = indices[maxi]\n",
    "        else:\n",
    "            try:\n",
    "                resi = random.randint(0, len(caSpans) - 1)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    elif questionType == 7:\n",
    "        for j in range(len(caSpans)):\n",
    "            caSpan = caSpans[j]\n",
    "            tokens = caSpan.tokens\n",
    "            catype = caSpan.answertype\n",
    "            tempStr = question.replace(qSpans.substiSection, \" \".join(tokens))\n",
    "            x = model.fit_transform([context, tempStr])\n",
    "            matrix = (x * x.T).A\n",
    "            score.append(matrix[0][1])\n",
    "            indices.append(j)\n",
    "        score = np.array(score)\n",
    "        if len(score) > 0:\n",
    "            maxi = np.argmax(score)\n",
    "            resi = indices[maxi]\n",
    "        else:\n",
    "            try:\n",
    "                resi = random.randint(0, len(caSpans) - 1)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    elif questionType == 4:\n",
    "        if \"how many\" in question:\n",
    "            for j in range(len(caSpans)):\n",
    "                caSpan = caSpans[j]\n",
    "                tokens = caSpan.tokens\n",
    "                catype = caSpan.answertype\n",
    "                if catype in NUMERICAL:\n",
    "                    tempStr = question.replace(\"how many\", \" \".join(tokens))\n",
    "                    x = model.fit_transform([context, strReplaced])\n",
    "                    matrix = (x * x.T).A\n",
    "                    score.append(matrix[0][1])\n",
    "                    indices.append(j)\n",
    "                    \n",
    "        elif \"how much\" in question:\n",
    "            for j in range(len(caSpans)):\n",
    "                caSpan = caSpans[j]\n",
    "                tokens = caSpan.tokens\n",
    "                catype = caSpan.answertype\n",
    "                if catype in NUMERICAL:\n",
    "                    tempStr = question.replace(\"how much\", \" \".join(tokens))\n",
    "                    x = model.fit_transform([context, strReplaced])\n",
    "                    matrix = (x * x.T).A\n",
    "                    score.append(matrix[0][1])\n",
    "                    indices.append(j)\n",
    "        \n",
    "        elif \"how long\" in question:\n",
    "            for j in range(len(caSpans)):\n",
    "                caSpan = caSpans[j]\n",
    "                tokens = caSpan.tokens\n",
    "                catype = caSpan.answertype\n",
    "                if catype in NUMERICAL or catype in TIME:\n",
    "                    tempStr = question.replace(\"how long\", \" \".join(tokens))\n",
    "                    x = model.fit_transform([context, strReplaced])\n",
    "                    matrix = (x * x.T).A\n",
    "                    score.append(matrix[0][1])\n",
    "                    indices.append(j)\n",
    "        \n",
    "        elif \"how old\" in question:\n",
    "            for j in range(len(caSpans)):\n",
    "                caSpan = caSpans[j]\n",
    "                tokens = caSpan.tokens\n",
    "                catype = caSpan.answertype\n",
    "                if catype in NUMERICAL or catype in TIME:\n",
    "                    tempStr = question.replace(\"how old\", \" \".join(tokens))\n",
    "                    x = model.fit_transform([context, strReplaced])\n",
    "                    matrix = (x * x.T).A\n",
    "                    score.append(matrix[0][1])\n",
    "                    indices.append(j)\n",
    "        \n",
    "        elif \"how far\" in question:\n",
    "            for j in range(len(caSpans)):\n",
    "                caSpan = caSpans[j]\n",
    "                tokens = caSpan.tokens\n",
    "                catype = caSpan.answertype\n",
    "                if catype in NUMERICAL:\n",
    "                    tempStr = question.replace(\"how far\", \" \".join(tokens))\n",
    "                    x = model.fit_transform([context, strReplaced])\n",
    "                    matrix = (x * x.T).A\n",
    "                    score.append(matrix[0][1])\n",
    "                    indices.append(j)\n",
    "        score = np.array(score)\n",
    "        if len(score) > 0:\n",
    "            maxi = np.argmax(score)\n",
    "            resi = indices[maxi]\n",
    "        else:\n",
    "            try:\n",
    "                resi = random.randint(0, len(caSpans) - 1)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        \n",
    "    elif questionType == 0:\n",
    "        for j in range(len(caSpans)):\n",
    "            caSpan = caSpans[j]\n",
    "            tokens = caSpan.tokens\n",
    "            catype = caSpan.answertype\n",
    "            tempStr = question.replace('what', \" \".join(tokens))\n",
    "            x = model.fit_transform([context, tempStr])\n",
    "            matrix = (x * x.T).A\n",
    "            score.append(matrix[0][1])\n",
    "            indices.append(j)\n",
    "        score = np.array(score)\n",
    "        if len(score) > 0:\n",
    "            maxi = np.argmax(score)\n",
    "            resi = indices[maxi]\n",
    "        else:\n",
    "            try:\n",
    "                resi = random.randint(0, len(caSpans) - 1)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            resi = random.randint(0, len(caSpans) - 1)\n",
    "        except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    return resi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input and output\n",
    "answerSet = defaultdict(str)\n",
    "inputFile = 'testInput.json'\n",
    "outputFile = 'result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read input file\n",
    "with open(inputFile, 'r') as file:\n",
    "    text = file.read()\n",
    "data = json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function\n",
    "with corenlp.CoreNLPClient(annotators='tokenize ssplit parse lemma pos ner'.split()) as client:\n",
    "    for document in data['data']:\n",
    "        paragraphs = defaultdict(list)\n",
    "        rawParagraphs = document['paragraphs']\n",
    "        for rawParagraph in rawParagraphs:\n",
    "            rawContext = rawParagraph['context']\n",
    "            qas = rawParagraph['qas']\n",
    "            \n",
    "            #process context\n",
    "            #filter out punctuations and transfer it to lowercase\n",
    "            tempContext = client.annotate(rawContext)\n",
    "            context = []\n",
    "            for s in tempContext.sentence:\n",
    "                sentence = []\n",
    "                for token in s.token:\n",
    "                    tempToken = token.lemma.lower()\n",
    "                    if tempToken not in PUNCTUATIONS:\n",
    "                        sentence.append(tempToken)\n",
    "                context.append(\" \".join(sentence))\n",
    "            \n",
    "            unigramModel = TFIDF(input=context, analyzer='word', dtype=np.float32, stop_words=STOPWORDS)\n",
    "            \n",
    "            for qa in qas:\n",
    "                rawQuestion = qa['question']\n",
    "                qid = qa['id']\n",
    "                \n",
    "                tempQuestion = client.annotate(rawQuestion)\n",
    "                question = []\n",
    "                \n",
    "                tokens = tempQuestion.sentence[0].token\n",
    "                isIdentified = False\n",
    "                questionType = 8\n",
    "                questionSpan = question_span()\n",
    "                for token in tokens:\n",
    "                    tempToken = token.lemma.lower()\n",
    "                    if tempToken not in PUNCTUATIONS:\n",
    "                        question.append(tempToken)\n",
    "                        if not isIdentified:\n",
    "                            if token == 'what':\n",
    "                                isIdentified = True\n",
    "                                pos = token.pos\n",
    "                                if pos == 'WP':\n",
    "                                    questionType = 0\n",
    "                                elif pos == 'WDT':\n",
    "                                    questionType = 7\n",
    "                                    questionSpan.substiSection = getReplacedPart(tempQuestion.sentence[0], questionType)\n",
    "                                else:\n",
    "                                    isIdentified = False\n",
    "                            elif token == 'who':\n",
    "                                isIdentified = True\n",
    "                                questionType = 1\n",
    "                            elif token == 'where':\n",
    "                                isIdentified = True\n",
    "                                questionType = 2\n",
    "                            elif token == 'when':\n",
    "                                isIdentified = True\n",
    "                                questionType = 3\n",
    "                            elif token == 'how':\n",
    "                                isIdentified = True\n",
    "                                questionType = 4\n",
    "                            elif token == 'why':\n",
    "                                isIdentified = True\n",
    "                                questionType = 5\n",
    "                            elif token == 'which':\n",
    "                                isIdentified = True\n",
    "                                questionType = 6\n",
    "                                questionSpan.substiSection = getReplacedPart(tempQuestion.sentence[0], questionType)\n",
    "                questionSpan.content = \" \".join(question)\n",
    "                questionSpan.questionType = questionType\n",
    "                \n",
    "                findMaxSimilarity = []\n",
    "                for con in context:\n",
    "                    ques = questionSpan.content\n",
    "                    combo = [con, ques]\n",
    "                    matrix = unigramModel.fit_transform(combo)\n",
    "                    tempScore = (matrix * matrix.T).A\n",
    "                    findMaxSimilarity.append(tempScore[0][1])\n",
    "                findMaxSimilarity = np.array(findMaxSimilarity)\n",
    "                maxi = np.argmax(findMaxSimilarity)\n",
    "                \n",
    "                candidateSentence = tempContext.sentence[maxi]\n",
    "                parseTree = candidateSentence.parseTree\n",
    "                \n",
    "                q = queue.Queue(maxsize=MAX_SIZE)\n",
    "                q.put(parseTree)\n",
    "                candidateAnswers = getAllNPTokens(q)\n",
    "                \n",
    "                candidateAnswerSpans = genCandidateAnswerSpans(candidateAnswers, candidateSentence.token)\n",
    "                size = len(candidateAnswerSpans)\n",
    "                \n",
    "                answerStr = \"\"\n",
    "                if len(candidateAnswerSpans) > 0:\n",
    "                    resi = getBestAnswer(candidateAnswerSpans, questionSpan, context[maxi], unigramModel)\n",
    "                    answerSpan = candidateAnswerSpans[resi]\n",
    "                    \n",
    "                    for j in range(len(answerSpan.tokens) - 1):\n",
    "                        answerStr += answerSpan.tokens[j] + \" \"\n",
    "                    answerStr += answerSpan.tokens[len(answerSpan.tokens) - 1]\n",
    "                answerSet[qid] = answerStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultJSON = json.dumps(answerSet)\n",
    "with open(outputFile, 'w') as fout:\n",
    "    fout.writelines(resultJSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
